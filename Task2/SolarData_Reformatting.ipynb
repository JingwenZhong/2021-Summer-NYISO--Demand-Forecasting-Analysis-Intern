{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Data Files Reformatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### change csv files to excel files (no need to use this, cause we want to work with .csv first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# change csv files to excel files:\n",
    "def csv_to_excel(filespath):\n",
    "    for filename in os.listdir(filespath): # os.listdir(path): return file names\n",
    "        file_path = os.path.join(filespath, filename)  \n",
    "        if file_path.endswith(\".csv\"):\n",
    "                csv_file = pd.read_csv(file_path)\n",
    "                csv_file.to_excel(filename[:-3]+'xlsx')\n",
    "                # os.remove(file_path) #delete .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### seperate/add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def shape_df(file): # input a file\n",
    "    \n",
    "    # if its .csv file:\n",
    "    # df = pd.read_csv(file) #  dataframe\n",
    "    \n",
    "    # if it's excel file:\n",
    "    df = pd.read_excel(file) #  dataframe\n",
    "    \n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    # seperate name by '_' and convert it in different columns, \n",
    "        # eg.'ZoneA_GHI_AWS' to 'ZoneA' 'GHI' 'AWS' 3 different columns\n",
    "    df_name = df['IMPORTID'].str.split(pat = '_',expand=True)\n",
    "    df[\"Zone\"] = df_name[0].str.strip().str[-1] #only use first column eg. A \n",
    "    df[\"Type\"] = df_name[1] # and sencond column eg. GHI\n",
    "    del df['IMPORTID']  # delete 'IMPORTID' column\n",
    "    \n",
    "    # Change the format of time:\n",
    "    df['DT'] = pd.to_datetime(df['DT'])\n",
    "    df['Date'] =  df['DT'].dt.date\n",
    "    df[\"Year\"] = df['DT'].dt.year #get year\n",
    "    df[\"Month\"] = df['DT'].dt.month #get month\n",
    "    df[\"Day\"] = df['DT'].dt.day #get day\n",
    "    df[\"Time\"] = df['DT'].dt.time  #get time\n",
    "    del df['DT']        # delete 'DT' column\n",
    "    \n",
    "    df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True)\n",
    "    return df # return a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add missing rows\n",
    "\n",
    "    Zone A to K: miss GHI, POA20, POA30 from 2017/01/01 ~ 2017/06/30\n",
    "    Zone Z: misses BTM, GHI, POA20, POA30 from 2017/01/01 ~ 2017/06/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing(df):\n",
    "    solar2017 = df.loc[(df['Date'] < date(2017,7,1))]\n",
    "    df_add_raw = pd.DataFrame(columns = solar2017.columns)\n",
    "\n",
    "    Zone_list = ['A','B','C','D','E','F','G','H','I','J','K']\n",
    "    Type_list = ['GHI','POA20','POA30']\n",
    "\n",
    "    # build a df \n",
    "    if len(solar2017)>0:\n",
    "        for Zone in Zone_list:\n",
    "            for j in Type_list:\n",
    "                df_add_raw = pd.DataFrame(columns = solar2017.columns) # create a dateframe\n",
    "                idx = pd.date_range(start = '2017-01-01', end = '2017-6-30 23:45:00', freq = '15T')\n",
    "                df_add_raw['Date'] = idx.date\n",
    "                df_add_raw['Year'] = idx.year\n",
    "                df_add_raw['Month'] = idx.month\n",
    "                df_add_raw['Day'] = idx.day\n",
    "                df_add_raw['Time'] = idx.time\n",
    "                df_add_raw['Zone'] = [\"%s\"%(Zone)]*len(idx)\n",
    "                df_add_raw['Type'] = [\"%s\"%(j)]*len(idx) \n",
    "                df = df.append(df_add_raw, ignore_index = True)\n",
    "                \n",
    "    df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperate/add columns by Types; and seperate files by Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def seperate_types_files(file, files_dir): # input is a file, and files_dir: where you want to store the new files\n",
    "    # get the file name:\n",
    "    filename = os.path.basename(file)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    \n",
    "    os.chdir(files_dir) # change the path to the directory\n",
    "\n",
    "    # if the zonal file is not in the directory:\n",
    "\n",
    "\n",
    "    df =  shape_df(file) # use function above to get the modified dataframe\n",
    "    #if has missing value in 2017 then use this:\n",
    "    #df = add_missing(df) # use function above to get missing value\n",
    "    \n",
    "\n",
    "    Zone_list = list(df['Zone'].unique()) # unique Zonal names\n",
    "    Zone_list.sort()\n",
    "    Type_list = list(df['Type'].unique()) # unique Types names\n",
    "    Type_list.sort()\n",
    "\n",
    "    #add hour flag column:\n",
    "    df['HrFlag'] = df['Time'].map(lambda x: 1 if x.hour >= 6 and x.hour <=19  else 0)\n",
    "\n",
    "    for i in Zone_list:\n",
    "        df_add = pd.DataFrame(columns = Type_list) # create a dateframe\n",
    "        file_cut = df[df['Zone']==i] # Seperate Zones\n",
    "\n",
    "        # Seperate Types to columes, and add them to a new dataframe:\n",
    "        for j in Type_list: \n",
    "            type_cut = file_cut.loc[file_cut['Type']==j]  \n",
    "            df_add[j] = type_cut['READING'].values\n",
    "\n",
    "        file_cut = file_cut.drop_duplicates(['Date','Time']).reset_index(drop = True) # Delete duplicated raws\n",
    "\n",
    "        del file_cut['Type'] # drop Types column\n",
    "        del file_cut['READING'] # drop READING column\n",
    "\n",
    "        final = pd.concat([file_cut,df_add], axis = 1, ignore_index=True) # combine the new dataframe to old one\n",
    "\n",
    "        # Rename the final dataframe: (depend on the output)\n",
    "        final.columns =  ['Zone', 'Date','Year', 'Month', 'Day', 'Time','HrFlag','BTM', 'GHI','POA20','POA30']\n",
    "        # final.columns =  ['Zone', 'Date','Year', 'Month', 'Day', 'Time','HrFlag','BTM'] \n",
    "\n",
    "        # If seperate zonal files:\n",
    "        #final.to_excel(r\"%s_%s.xlsx\"%(i, filename), 'sheet1',index=False) # create a excel file\n",
    "\n",
    "        #deal with any kind of files:\n",
    "        final.to_excel(r\"%s.xlsx\"%(i), 'sheet1',index=False) # create a excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deal with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir_old = 'C:/Users/zhongj/Desktop/New folder' # change the directory\n",
    "\n",
    "files_dir_new = \"C:/Users/zhongj/Desktop/New folder3\" # change the directory\n",
    "\n",
    "\n",
    "for filename in os.listdir(files_dir_old):\n",
    "    file_path = os.path.join(files_dir_old, filename)\n",
    "    seperate_types_files(file_path, files_dir_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine files \n",
    "(I didn't use this code, because combine directly using excel, we can change the format of date, but this code can't)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir_old = \"C:/Users/zhongj/Desktop/SolarData_Edit\" # change the directory\n",
    "\n",
    "files_dir_new= 'C:/Users/zhongj/Desktop/Zonal_SolarData' # change the directory\n",
    "\n",
    "import xlrd\n",
    "import xlsxwriter\n",
    "\n",
    "Zones = ['A_Solar_Data','B_Solar_Data','C_Solar_Data','D_Solar_Data','E_Solar_Data','F_Solar_Data',\n",
    "         'G_Solar_Data','H_Solar_Data','I_Solar_Data','J_Solar_Data','K_Solar_Data','S_Solar_Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # a list\n",
    "for zone in Zones: # for each zone\n",
    "    \n",
    "    for filename in os.listdir(files_dir_old): # for each files\n",
    "        file_path = os.path.join(files_dir_old, filename)\n",
    "        \n",
    "        # if the zone name in file names:\n",
    "        if zone in filename:  \n",
    "            wb = xlrd.open_workbook(file_path) #open excel file\n",
    "            sheet =  wb.sheets()[0] #only have one sheet\n",
    "            \n",
    "            for rownum in range(sheet.nrows):\n",
    "                data.append(sheet.row_values(rownum)) # put data in the list\n",
    "                \n",
    "    os.chdir(files_dir_new)\n",
    "    \n",
    "    #create an excel:\n",
    "    workbook = xlsxwriter.Workbook(r\"%s.xlsx\"%(zone))\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    # font = workbook.add_format({'font_size':12})\n",
    "    \n",
    "    # write the data into excel:\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            worksheet.write(i, j, data[i][j])\n",
    "    workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
