{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data Files Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_df(file):\n",
    "    df = pd.read_csv(file) #read files\n",
    "    df = df.loc[:, ['ZONE_CODE','LPT_START_DT', 'WEATHER_CONCEPT_CODE','WEATHER_VALUE']] #only use these columns\n",
    "    df.columns = ['Zone', 'DT', 'Type', 'Value'] #change a easy name\n",
    "    \n",
    "    df['DT'] = pd.to_datetime(df['DT']) #change time format\n",
    "    \n",
    "    df['Date'] =  df['DT'].dt.date # get date\n",
    "    df[\"Time\"] = df['DT'].dt.time  #get time\n",
    "    \n",
    "    del df['DT'] #drop DT column\n",
    "    \n",
    "    df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True) #sort data\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### check how the data look like by zones and by types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_dir = 'C:/Users/zhongj/Desktop/WeatherData' # change the directory\n",
    "os.chdir(files_dir)\n",
    "\n",
    "df = shape_df('weather_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zone_list = list(df['Zone'].unique()) # unique Zonal names\n",
    "Type_list = list(df['Type'].unique()) # unique Types names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in Zone_list:\n",
    "#     print(df[df['Zone']==j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### check what time/date is missing or duplicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_list = list(df['Time'].unique())\n",
    "Date_list = list(df['Date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-08 23\n"
     ]
    }
   ],
   "source": [
    "for j in Date_list:\n",
    "    a = list(df[(df['Type']=='WSP')&(df['Zone']== 'K')]['Date']).count(j)\n",
    "    if a < 24:\n",
    "        print(j, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in Time_list:\n",
    "    a = list(df[(df['Type']=='WSP')&(df['Zone']== 'A')]['Time']).count(j)\n",
    "    print(j, a)\n",
    "### from here we know that 1am has a dupicated row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 2\n"
     ]
    }
   ],
   "source": [
    "## check duplicated raws:\n",
    "\n",
    "import datetime\n",
    "\n",
    "Date_list = list(df['Date'].unique())\n",
    "\n",
    "for j in Date_list:\n",
    "    a = list(df[(df['Type']=='WSP')&(df['Zone']== 'A')&(df['Time'] == datetime.time(1,0))]['Date']).count(j)\n",
    "    if a > 1:\n",
    "        print(j, a)\n",
    "\n",
    "### from here we know 11.05 1:00:00 has a duplicated raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Zone, Type, Value, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ (df['Type']=='GHI60') & (df['Zone']== 'G') & (df['Time'] == datetime.time(1,0)) & (df['Date'] == date(2020,11,1)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check duplicated raws:\n",
    "\n",
    "import datetime\n",
    "\n",
    "Date_list = list(df['Date'].unique())\n",
    "\n",
    "for j in Date_list:\n",
    "    a = list(df[(df['Type']=='WSP')&(df['Zone']== 'A')&(df['Time'] == datetime.time(23,0))]['Date']).count(j)\n",
    "    if a > 1:\n",
    "        print(j, a)\n",
    "\n",
    "### from here we know 11-05-2017 1:00:00 has a duplicated raw\n",
    "### and 11-01-2020 1:00:00 has a duplicated raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add missing rows and delet the dupicates \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing(df): \n",
    "    \n",
    "    # Delete duplicated raws:\n",
    "    df = df.drop_duplicates(['Zone','Type','Date','Time', 'Value']).reset_index(drop = True)\n",
    "    Zone_list = list(df['Zone'].unique()) # unique Zonal names\n",
    "    Type_list = list(df['Type'].unique()) # unique Types names\n",
    "    \n",
    "    #2017:\n",
    "    if len(df.loc[(df['Date'] <= date(2017,12,31))]) > 0:\n",
    "\n",
    "        # Add missing GHI60, SSM, THI, WCI, WDR raws: \n",
    "        for Zone in Zone_list:\n",
    "            for j in Type_list:\n",
    "                if len(df.loc[(df['Date'] < date(2017,10,29)) & (df['Type']== j) & (df['Zone']== Zone)]) == 0:\n",
    "                    df_add_raw = pd.DataFrame(columns = df.columns) # create a dateframe\n",
    "                    idx = pd.date_range(start = '2017-01-01', end = '2017-10-28 23:00:00', freq = 'H')\n",
    "                    df_add_raw['Zone'] = [\"%s\"%(Zone)]*len(idx)\n",
    "                    df_add_raw['Type'] = [\"%s\"%(j)]*len(idx) \n",
    "                    df_add_raw['Date'] = idx.date\n",
    "                    df_add_raw['Time'] = idx.time\n",
    "\n",
    "                    df = df.append(df_add_raw, ignore_index = True)\n",
    "\n",
    "        df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True)\n",
    "\n",
    "        # Add missing CLC, DBT60, DEW, WET, WSP raw: \n",
    "        Time_list = list(df['Time'].unique())\n",
    "        Date_list = list(df['Date'].unique())\n",
    "        type_list = ['CLC','DBT60','DEW','WET','WSP'] \n",
    "\n",
    "        # Find dates that have missing times:\n",
    "        miss_date = []\n",
    "        for j in Date_list:\n",
    "            a = list(df[(df['Type']=='WSP')&(df['Zone']== 'A')]['Date']).count(j)\n",
    "            if a < 24:\n",
    "                miss_date.append(j)\n",
    "\n",
    "        # add raws:\n",
    "        df_add_raw = pd.DataFrame(columns = df.columns)\n",
    "        for Zone in Zone_list:\n",
    "            for j in Type_list:\n",
    "                df_cut = df[(df['Type']==j) & (df['Zone']== Zone)] \n",
    "\n",
    "                for i in miss_date:\n",
    "                    time_list = list(df_cut[(df['Date'] == i)]['Time'].unique()) # times that occur in that day\n",
    "                    miss_time = list(set(Time_list) - set(time_list)) #find what times are missing in that day\n",
    "\n",
    "                    #add the time:\n",
    "                    for t in miss_time:                \n",
    "                        df_add_raw.loc[df_add_raw.shape[0]] = dict(zip(df_add_raw.columns, \n",
    "                                                                       (\"%s\"%(Zone), \"%s\"%(j), None, \n",
    "                                                                        i, t)))\n",
    "\n",
    "        df = df.append(df_add_raw, ignore_index = True)\n",
    "        df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # 2020\n",
    "    if len(df.loc[(df['Date'] >= date(2020,1,1))]) > 0:\n",
    "        # add raws:\n",
    "        for Zone in Zone_list:\n",
    "            for j in Type_list:\n",
    "                df.loc[df.shape[0]] = dict(zip(df.columns, \n",
    "                                               (\"%s\"%(Zone), \"%s\"%(j), None,\n",
    "                                                date(2020,3,8), datetime.time(2,0))))\n",
    "\n",
    "        df = df.sort_values(by = ['Zone','Type','Date','Time']).reset_index(drop = True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # 2018, 2019\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### seperate/add columns by Types; and seperate files by Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def seperate_types_files(file, files_dir): # input is a file, and files_dir: where you want to store the new files\n",
    "    # get the file name:\n",
    "    filename = os.path.basename(file)\n",
    "    filename = os.path.splitext(filename)[0] \n",
    "    \n",
    "    df =  shape_df(file) # use function above to get the modified dataframe\n",
    "    df = add_missing(df) # use function above to get the modified dataframe\n",
    "    \n",
    "    Zone_list = list(df['Zone'].unique()) # unique Zonal names\n",
    "    Zone_list.sort()\n",
    "    Type_list = list(df['Type'].unique()) # unique Types names\n",
    "    Type_list.sort()\n",
    "    \n",
    "    \n",
    "    for i in Zone_list:\n",
    "        \n",
    "        os.chdir(files_dir) # change the path to the directory\n",
    "        \n",
    "        # if the zonal file is not in the directory:\n",
    "        if os.path.exists(\"%s_%s\"%(i, filename)):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            df_add = pd.DataFrame(columns = Type_list) # create a dateframe\n",
    "            file_cut = df[df['Zone']==i] # Seperate Zones\n",
    "\n",
    "            # Seperate Types to columes, and add them to a new dataframe:\n",
    "            for j in Type_list: \n",
    "                type_cut = file_cut.loc[file_cut['Type']==j]  \n",
    "                df_add[j] = type_cut['Value'].values\n",
    "\n",
    "            file_cut = file_cut.drop_duplicates(['Date','Time']).reset_index(drop = True) # Delete duplicated raws\n",
    "\n",
    "            del file_cut['Type'] # drop Types column\n",
    "            del file_cut['Value'] # drop READING column\n",
    "\n",
    "            final = pd.concat([file_cut,df_add], axis = 1, ignore_index=True) # combine the new dataframe to old one\n",
    "\n",
    "            # Rename the final dataframe:\n",
    "                ## underscore means its weather data\n",
    "            final.columns =  ['Zone', 'Date','Time' ,\n",
    "                              '_CLC', '_DBT60', '_DEW', '_GHI60','_SSM', \n",
    "                              '_THI', '_WCI', '_WDR', '_WET', '_WSP'] \n",
    "\n",
    "\n",
    "            final.to_excel(r\"%s_%s.xlsx\"%(i, filename), 'sheet1', index=False) # create a excel file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "files_dir_old = 'C:/Users/zhongj/Desktop/WeatherData' # change the directory\n",
    "\n",
    "files_dir_new = \"C:/Users/zhongj/Desktop/WeatherData_Edit\" # change the directory\n",
    "\n",
    "\n",
    "for filename in os.listdir(files_dir_old):\n",
    "    file_path = os.path.join(files_dir_old, filename)\n",
    "    seperate_types_files(file_path, files_dir_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
